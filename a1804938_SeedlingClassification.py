# -*- coding: utf-8 -*-
"""DM_Mukul of DifferentTry4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iFW1tfxpAqVB0kooFT9Y7S6Jr8aBUll3
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

import numpy as np
import pandas as pd 

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
'''for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))'''

# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

#importing the nesce
import numpy as np
import itertools
import pandas as pd
import os
import math
import random
import cv2
import sys
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator

from glob import glob

scale = 80  # px to scale
seed = 8  # fixing random

from tensorflow.keras import optimizers

train_dir = "/content/gdrive/My Drive/Plant_Seedlings_Classification/train"
test_dir = "/content/gdrive/My Drive/Plant_Seedlings_Classification/test/*/*.png/"
save_dir = "/content/gdrive/My Drive/train"
target_size = (224, 224)

# Get names of all the categories 
categories = [category for category in sorted(os.listdir(train_dir))]

# Get the number of images in each cateogry
images_per_category = [len(os.listdir(os.path.join(train_dir, category))) for category in categories]

# Plot to see the distribution
plt.figure(figsize=(24,12))
sns.barplot(categories, images_per_category)



path_train = '/content/gdrive/My Drive/Plant_Seedlings_Classification/train/*/*.png'
images = glob(path_train)



training = []
training_labels = []
j = 1
num = len(images)

# Obtain images and resizing, obtain labels
for img in images:
    print(str(j) + "/" + str(num), end="\r")
    training.append(cv2.resize(cv2.imread(img), (scale, scale)))  # Get image (with resizing)
    training_labels.append(img.split('/')[-2])  # Get image label (folder name)
    j += 1

training = np.asarray(training)  # Train images set
training_labels = pd.DataFrame(training_labels)  # Train labels set

#Image preprocessing and cleaning the images

new_train_data = []
sets = []; 
get_image = True
for i in training:
    
    #blurring the image to remove noise
    blurr = cv2.GaussianBlur(i,(5,5),0)
    
    #Coverting the image to hsv colorspace
    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)
    
    lower = (25,50,60)
    upper = (55,255,255)
    
    #masking the images to remove background
    masking = cv2.inRange(hsv,lower,upper)
    struct = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))
    masking = cv2.morphologyEx(masking,cv2.MORPH_CLOSE,struct)
    boolean = masking>0
    new = np.zeros_like(i,np.uint8)
    new[boolean] = i[boolean]
    new_train_data.append(new)
    
    if get_image:
        plt.subplot(2,3,1);plt.imshow(i) # ORIGINAL
        plt.title('Original')

        plt.subplot(2,3,2);plt.imshow(blurr) # BLURRED
        plt.title('Blurred')

        plt.subplot(2,3,3);plt.imshow(hsv) # HSV CONVERTED
        plt.title('HSV')
        
       
        plt.subplot(2,3,4);plt.imshow(masking) # MASKED
        plt.title('Masked')

        plt.subplot(2,3,5);plt.imshow(boolean) # BOOLEAN MASKED
      

        plt.subplot(2,3,6);plt.imshow(new) # NEW PROCESSED IMAGE
        plt.title('New')

        plt.show()
        get_image = False
new_train_data = np.asarray(new_train_data)

# Processed IMAGES
for i in range(10):
    plt.subplot(3,5,i+1)
    
    plt.imshow(new_train_data[i])

#Printing the names of all the labels with the number of samples

category=[]
for i in os.listdir(train_dir):
    
    category.append(i)
print('Species wise images in the dataset:')
print('')

for u in category:
    count= len(os.listdir(os.path.join(train_dir,u )))
    print('{} images for  {} category'.format(count,u))
#return count

#Label Encoding as they are strings not numbers
from sklearn import preprocessing
from keras.utils import np_utils


label=preprocessing.LabelEncoder()
label.fit(training_labels[0])
new_label_name=label.transform(training_labels[0])

clearall = np_utils.to_categorical(new_label_name)
classes = clearall.shape[1]
#print(str(classes))
training_labels[0].value_counts().plot(kind='bar',cmap='Blues_r')

from sklearn.model_selection import train_test_split

#splitting the dataset into training and testing for validation
x_train,x_test,y_train,y_test = train_test_split(new_train_data,clearall,test_size=0.1,random_state=seed,stratify=clearall)

x_train.shape

import numpy
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers import BatchNormalization



numpy.random.seed(seed)  # Fix seed

model = Sequential()

model.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(scale, scale, 3), activation='relu'))
model.add(BatchNormalization(axis=3))
model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization(axis=3))
model.add(Dropout(0.1))

model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))
model.add(BatchNormalization(axis=3))
model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization(axis=3))
model.add(Dropout(0.1))

model.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))
model.add(BatchNormalization(axis=3))
model.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization(axis=3))
model.add(Dropout(0.1))

model.add(Flatten())

model.add(Dense(256, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Dense(256, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Dense(classes, activation='softmax'))

model.summary()

# compile model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
        rotation_range=180,  # randomly rotate images in the range
        zoom_range = 0.1, # Randomly zoom image 
        width_shift_range=0.1,  # randomly shift images horizontally
        height_shift_range=0.1,  # randomly shift images vertically 
        horizontal_flip=True,  # randomly flip images horizontally
        vertical_flip=True  # randomly flip images vertically
    )  
datagen.fit(x_train)

from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger

# learning rate reduction
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', 
                                            patience=3, 
                                            verbose=1, 
                                            factor=0.4, 
                                            min_lr=0.00001)

# checkpoints
#filepath="drive/DataScience/PlantReco/weights.best_{epoch:02d}-{val_acc:.2f}.hdf5"
filepath="/content/gdrive/My Drive/train/weights.best.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', 
                             verbose=1, save_best_only=True, mode='max')

filepath="/content/gdrive/My Drive/train/weights.last_auto4.hdf5"
checkpoint_all = ModelCheckpoint(filepath, monitor='val_accuracy', 
                                 verbose=1, save_best_only=False, mode='max')

# all callbacks
callbacks_list = [checkpoint, learning_rate_reduction, checkpoint_all]

# fit model
hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=64), 
                           epochs=50, validation_data=(x_test, y_test), 
                           steps_per_epoch= (x_train.shape[0]//64), callbacks=callbacks_list)

print(model.evaluate(x_train, y_train))  # Evaluate on train set
print(model.evaluate(x_test, y_test))  # Evaluate on test set

def plot_loss_curves(history):
    plt.style.use('seaborn')
    '''
    Args:
    history(History callback): which has a history attribute containing the lists of successive losses and other metrics
    '''
    plt.style.use('seaborn')
    NUM_EPOCHS = len(history.history['loss'])
    plt.style.use("ggplot")
    plt.figure(figsize=(16,10))
    plt.plot(np.arange(0, NUM_EPOCHS), history.history['loss'], label='train_loss')
    plt.plot(np.arange(0, NUM_EPOCHS), history.history['val_loss'], label='val_loss')
    plt.title("Training Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend(loc = 'upper left')
    plt.tight_layout()
    plt.show()

def plot_curves( history):
    plt.style.use('seaborn')
    '''
    Args:
    history(History callback): which has a history attribute containing the lists of successive losses and other metrics
    '''
    plt.style.use('seaborn')
    NUM_EPOCHS = len(history.history['loss'])
    plt.style.use("ggplot")
    plt.figure(figsize=(16,10))
    plt.plot(np.arange(0, NUM_EPOCHS), history.history['accuracy'], label='train_acc')
    plt.plot(np.arange(0, NUM_EPOCHS), history.history['val_accuracy'], label='val_acc')
    plt.title("Training Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend(loc = 'upper left')
    plt.tight_layout()
    plt.show()

plot_loss_curves(hist)

plot_curves(hist)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

from sklearn.metrics import classification_report
import itertools

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    
    fig = plt.figure(figsize=(10,10))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

# Predict the values from the validation dataset
predY = model.predict(x_test)
predYClasses = np.argmax(predY, axis = 1) 
trueY = np.argmax(y_test, axis = 1) 

# confusion matrix
confusionMTX = confusion_matrix(trueY, predYClasses) 

# plot the confusion matrix
plot_confusion_matrix(confusionMTX, classes = label.classes_)

test_path = "/content/gdrive/My Drive/Plant_Seedlings_Classification/test/*.png"
files = glob(test_path)

testImg = []
testId = []
j = 1
num = len(files)

# Obtain images and resizing, obtain labels
for img in files:
    print("Obtain images: " + str(j) + "/" + str(num), end='\r')
    testId.append(img.split('/')[-1])  # Images id's
    testImg.append(cv2.resize(cv2.imread(img), (scale, scale)))
    j += 1

testImg = np.asarray(testImg)  # Train images set

testImg.shape

for i in range(8):
    plt.subplot(2, 4, i + 1)
    plt.imshow(testImg[i])

clearTestImg = []
examples = []; getEx = True
for img in testImg:
    # Use gaussian blur
    blurImg = cv2.GaussianBlur(img, (5, 5), 0)   
    
    # Convert to HSV image
    hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)  
    
    # Create mask (parameters - green color range)
    lower_green = (25, 40, 50)
    upper_green = (75, 255, 255)
    mask = cv2.inRange(hsvImg, lower_green, upper_green)  
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    
    # Create bool mask
    bMask = mask > 0  
    
    # Apply the mask
    clear = np.zeros_like(img, np.uint8)  # Create empty image
    clear[bMask] = img[bMask]  # Apply boolean mask to the origin image
    
    clearTestImg.append(clear)  # Append image without backgroung
    
    # Show examples
    if getEx:
        plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image
        plt.subplot(2, 3, 2); plt.imshow(blurImg)  # Blur image
        plt.subplot(2, 3, 3); plt.imshow(hsvImg)  # HSV image
        plt.subplot(2, 3, 4); plt.imshow(mask)  # Mask
        plt.subplot(2, 3, 5); plt.imshow(bMask)  # Boolean mask
        plt.subplot(2, 3, 6); plt.imshow(clear)  # Image without background
        getEx = False

clearTestImg = np.asarray(clearTestImg)

# Show sample result
for i in range(8):
    plt.subplot(2, 4, i + 1)
    plt.imshow(clearTestImg[i])

clearTestImg = clearTestImg / 255

clearTestImg.shape

pred = model.predict(clearTestImg)

# Write result to file
predNum = np.argmax(pred, axis=1)
predStr = label.classes_[predNum]
res = {'file': testId, 'species': predStr}
res = pd.DataFrame(res)
res.to_csv("/content/gdrive/My Drive/train/Basic_res.csv", index=False)



"""VGG16"""

#VGG16

from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications import vgg16

model_save_path = '/content/gdrive/My Drive/train/model_vgg16.h5'

vgg16_base_model = VGG16(weights='imagenet',
                    include_top=False,    
                    classes=12,                
                    input_shape=(80,80,3)# input: 80x80 images with 3 channels -> (80, 80, 3) tensors.
                   )

#Define the sequential model and add th VGG's layers to it
vgg16_model = Sequential()
for layer in vgg16_base_model.layers:
    vgg16_model.add(layer)

# Adding hiddens  and output layer to our model

from tensorflow.keras.layers import Dense, Flatten, Dropout
vgg16_model.add(Flatten())
vgg16_model.add(Dense(512, activation='relu', name='hidden1'))
vgg16_model.add(Dropout(0.4))
vgg16_model.add(Dense(256, activation='relu', name='hidden2'))
vgg16_model.add(Dropout(0.4))
vgg16_model.add(Dense(12, activation='softmax', name='predictions'))


vgg16_model.summary()

from keras.optimizers import Adam
# CNN Trained on training data

# initiate SGD optimizer
sgd = optimizers.SGD(lr=0.001, momentum=0.9)

# For a multi-class classification problem
#vgg16_model.compile(loss='categorical_crossentropy',optimizer= sgd,metrics=['accuracy'])

# Compile the model    
vgg16_model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])

# learning rate reduction
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', 
                                            patience=5, 
                                            verbose=1, 
                                            factor=0.4, 
                                            min_lr=0.00001)

# checkpoints
#filepath="drive/DataScience/PlantReco/weights.best_{epoch:02d}-{val_acc:.2f}.hdf5"
filepath="/content/gdrive/My Drive/train/weights.best.model_vgg16.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', 
                             verbose=1, save_best_only=True, mode='max')

filepath="/content/gdrive/My Drive/train/weights.last_auto4.model_vgg16.hdf5"
checkpoint_all = ModelCheckpoint(filepath, monitor='val_accuracy', 
                                 verbose=1, save_best_only=False, mode='max')

# all callbacks
callbacks_list = [checkpoint, learning_rate_reduction, checkpoint_all]

# initialize the number of epochs and batch size
EPOCHS = 50
batch_sze = 64

# construct the training image generator for data augmentation
#aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,horizontal_flip=True, fill_mode="nearest")

from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
        rotation_range=180,  # randomly rotate images in the range
        zoom_range = 0.1, # Randomly zoom image 
        width_shift_range=0.1,  # randomly shift images horizontally
        height_shift_range=0.1,  # randomly shift images vertically 
        horizontal_flip=True,  # randomly flip images horizontally
        vertical_flip=True  # randomly flip images vertically
    )  
datagen.fit(x_train)

# train the model
history_vgg = vgg16_model.fit(datagen.flow(x_train,y_train, batch_size=batch_sze),validation_data=(x_test,y_test), 
                              steps_per_epoch=(len(x_train) // batch_sze),epochs=EPOCHS,callbacks=callbacks_list)

print(vgg16_model.evaluate(x_train, y_train))  # Evaluate on train set
print(vgg16_model.evaluate(x_test, y_test))  # Evaluate on test set

#Save the best model
vgg16_model.save('vgg_best_model.h5')

plot_loss_curves(history_vgg)

plot_curves(history_vgg)

# Predict the values from the validation dataset
predY = vgg16_model.predict(x_test)
predYClasses = np.argmax(predY, axis = 1) 
trueY = np.argmax(y_test, axis = 1) 

# confusion matrix
confusionMTX = confusion_matrix(trueY, predYClasses) 

# plot the confusion matrix
plot_confusion_matrix(confusionMTX, classes = label.classes_)

"""Test CSV prediction"""

pred = vgg16_model.predict(clearTestImg)

# Write result to file
predNum = np.argmax(pred, axis=1)
predStr = label.classes_[predNum]
res = {'file': testId, 'species': predStr}
res = pd.DataFrame(res)
res.to_csv("/content/gdrive/My Drive/train/VGG16_res.csv", index=False)



"""Applying SVM"""

from keras.models import  Model

model_feat = Model(inputs=vgg16_model.input,outputs=vgg16_model.get_layer('hidden2').output)

feat_train = model_feat.predict(x_train)
print(feat_train.shape)

feat_val = model_feat.predict(x_test)
print(feat_val.shape)

feat_test = model_feat.predict(clearTestImg)
print(feat_test.shape)

from sklearn.svm import SVC

svm = SVC(kernel='rbf')

svm.fit(feat_train,np.argmax(y_train,axis=1))

print('fitting done !!!')

svm.score(feat_train,np.argmax(y_train,axis=1))

"""Prediction Score [Validation Features]"""

svm.score(feat_val,np.argmax(y_test,axis=1))



"""Applying XGBOOST"""

import xgboost as xgb

xb = xgb.XGBClassifier()

xb.fit(feat_train,np.argmax(y_train,axis=1))

print('fitting done !!!')

xb.score(feat_train,np.argmax(y_train,axis=1))

xb.score(feat_val,np.argmax(y_test,axis=1))



"""RESNET-50"""

#ResNet50
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications import resnet50
from keras.applications.resnet50 import preprocess_input as resnet_preprocess_input



import tensorflow.keras as K

input_t = K.Input(shape=(80,80,3))
resnet50_base_model = ResNet50(weights='imagenet',
                    include_top=False,                    
                    input_tensor=input_t# input: 80x80 images with 3 channels -> (80, 80, 3) tensors.
                   )

for layer in resnet50_base_model.layers[:143]:
    layer.trainable = False

to_res = (80, 80)
resnet50_model = K.models.Sequential()
resnet50_model.add(K.layers.Lambda(lambda image: tf.image.resize(image, to_res))) 
resnet50_model.add(resnet50_base_model)
resnet50_model.add(K.layers.Flatten())
resnet50_model.add(K.layers.BatchNormalization())
resnet50_model.add(K.layers.Dense(256, activation='relu'))
resnet50_model.add(K.layers.Dropout(0.5))
resnet50_model.add(K.layers.BatchNormalization())
resnet50_model.add(K.layers.Dense(128, activation='relu'))
resnet50_model.add(K.layers.Dropout(0.5))
resnet50_model.add(K.layers.BatchNormalization())
resnet50_model.add(K.layers.Dense(64, activation='relu'))
resnet50_model.add(K.layers.Dropout(0.5))
resnet50_model.add(K.layers.BatchNormalization())
resnet50_model.add(K.layers.Dense(12, activation='softmax'))

# CNN Trained on training data

# initiate SGD optimizer
sgd = optimizers.SGD(lr=0.001, momentum=0.9)

# For a multi-class classification problem
resnet50_model.compile(loss='categorical_crossentropy',optimizer=K.optimizers.RMSprop(lr=2e-5),metrics=['accuracy'])



# learning rate reduction
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', 
                                            patience=5, 
                                            verbose=1, 
                                            factor=0.4, 
                                            min_lr=0.00001)

# checkpoints
#filepath="drive/DataScience/PlantReco/weights.best_{epoch:02d}-{val_acc:.2f}.hdf5"
filepath="/content/gdrive/My Drive/train/weights.best.model_resnet50.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', 
                             verbose=1, save_best_only=True, mode='max')

filepath="/content/gdrive/My Drive/train/weights.last_auto4.model_resnet50.hdf5"
checkpoint_all = ModelCheckpoint(filepath, monitor='val_accuracy', 
                                 verbose=1, save_best_only=False, mode='max')

# all callbacks
callbacks_list = [checkpoint, learning_rate_reduction, checkpoint_all]

# train the model
history_resnet50 = resnet50_model.fit(aug.flow(x_train,y_train, batch_size=batch_sze),validation_data=(x_test,y_test), 
                              steps_per_epoch=len(x_train) // batch_sze,epochs=EPOCHS,callbacks=callbacks_list)

print(resnet50_model.evaluate(x_train, y_train))  # Evaluate on train set
print(resnet50_model.evaluate(x_test, y_test))  # Evaluate on test set

plot_loss_curves(history_resnet50)

plot_curves(history_resnet50)

# Predict the values from the validation dataset
predY = resnet50_model.predict(x_test)
predYClasses = np.argmax(predY, axis = 1) 
trueY = np.argmax(y_test, axis = 1) 

# confusion matrix
confusionMTX = confusion_matrix(trueY, predYClasses) 

# plot the confusion matrix
plot_confusion_matrix(confusionMTX, classes = label.classes_)

pred = resnet50_model.predict(clearTestImg)
# Write result to file
predNum = np.argmax(pred, axis=1)
predStr = label.classes_[predNum]
res = {'file': testId, 'species': predStr}
res = pd.DataFrame(res)
res.to_csv("/content/gdrive/My Drive/train/Resnet50_res.csv", index=False)